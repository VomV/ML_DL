{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:03<00:00, 7862749.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 1212914.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:00<00:00, 5077844.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 9863991.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "                                    root='data',\n",
    "                                    download='True',\n",
    "                                    train='True',\n",
    "                                    transform=ToTensor(),\n",
    "\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "                                    root='data',\n",
    "                                    download='True',\n",
    "                                    train='False',\n",
    "                                    transform=ToTensor(),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a Neural Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "                                                nn.Linear(28*28, 512),\n",
    "                                                nn.ReLU(),\n",
    "                                                nn.Linear(512, 512),\n",
    "                                                nn.ReLU(),\n",
    "                                                nn.Linear(512, 10)\n",
    "                                            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 2e-3\n",
    "batch_size = 64\n",
    "epochs = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer to update the model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Steps of optimizationm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reset the gradients of model params optimizer.zero_grad()\n",
    "- Backpropagate the prediction loss with loss.backward(). Record gradient of loss wrt each param.\n",
    "- Update the params with gradients collected in backward pass optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    for  batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        #Prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        #Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #print loss every 100 epochs\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss}', f'current: {current}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct  = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Accuracy: {100*correct}', f'Avg loss: {test_loss}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise the loss and optimizer, and pass to train and test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch::: 1\n",
      "---------------\n",
      "loss: 1.8821470737457275 current: 0\n",
      "loss: 1.8111536502838135 current: 6400\n",
      "loss: 1.638181447982788 current: 12800\n",
      "loss: 1.6668294668197632 current: 19200\n",
      "loss: 1.5005906820297241 current: 25600\n",
      "loss: 1.4504729509353638 current: 32000\n",
      "loss: 1.43965482711792 current: 38400\n",
      "loss: 1.3389925956726074 current: 44800\n",
      "loss: 1.343194603919983 current: 51200\n",
      "loss: 1.2226999998092651 current: 57600\n",
      "Accuracy: 63.54666666666666 Avg loss: 1.233265733413859\n",
      "Epoch::: 2\n",
      "---------------\n",
      "loss: 1.3171625137329102 current: 0\n",
      "loss: 1.2770317792892456 current: 6400\n",
      "loss: 1.0923062562942505 current: 12800\n",
      "loss: 1.198470115661621 current: 19200\n",
      "loss: 1.048308253288269 current: 25600\n",
      "loss: 1.070151686668396 current: 32000\n",
      "loss: 1.0853731632232666 current: 38400\n",
      "loss: 1.0226857662200928 current: 44800\n",
      "loss: 1.0491219758987427 current: 51200\n",
      "loss: 0.9650514125823975 current: 57600\n",
      "Accuracy: 66.875 Avg loss: 0.9678520476385983\n",
      "Epoch::: 3\n",
      "---------------\n",
      "loss: 1.0346461534500122 current: 0\n",
      "loss: 1.0460275411605835 current: 6400\n",
      "loss: 0.8397738337516785 current: 12800\n",
      "loss: 1.0009844303131104 current: 19200\n",
      "loss: 0.8628764748573303 current: 25600\n",
      "loss: 0.8846556544303894 current: 32000\n",
      "loss: 0.9377355575561523 current: 38400\n",
      "loss: 0.886884868144989 current: 44800\n",
      "loss: 0.9083439707756042 current: 51200\n",
      "loss: 0.8503091335296631 current: 57600\n",
      "Accuracy: 69.52333333333334 Avg loss: 0.8425746271605177\n",
      "Epoch::: 4\n",
      "---------------\n",
      "loss: 0.8810800909996033 current: 0\n",
      "loss: 0.9317576289176941 current: 6400\n",
      "loss: 0.7081628441810608 current: 12800\n",
      "loss: 0.8989558219909668 current: 19200\n",
      "loss: 0.7767226696014404 current: 25600\n",
      "loss: 0.782416045665741 current: 32000\n",
      "loss: 0.8574306964874268 current: 38400\n",
      "loss: 0.8213170170783997 current: 44800\n",
      "loss: 0.8297678828239441 current: 51200\n",
      "loss: 0.7849867939949036 current: 57600\n",
      "Accuracy: 72.02833333333334 Avg loss: 0.7708220753207136\n",
      "Epoch::: 5\n",
      "---------------\n",
      "loss: 0.7848718762397766 current: 0\n",
      "loss: 0.8591442108154297 current: 6400\n",
      "loss: 0.6283890604972839 current: 12800\n",
      "loss: 0.8369917273521423 current: 19200\n",
      "loss: 0.7262265086174011 current: 25600\n",
      "loss: 0.7201743721961975 current: 32000\n",
      "loss: 0.8009581565856934 current: 38400\n",
      "loss: 0.7822514176368713 current: 44800\n",
      "loss: 0.7788317203521729 current: 51200\n",
      "loss: 0.739602267742157 current: 57600\n",
      "Accuracy: 74.29666666666667 Avg loss: 0.7214848012494635\n",
      "Epoch::: 6\n",
      "---------------\n",
      "loss: 0.715976357460022 current: 0\n",
      "loss: 0.8034171462059021 current: 6400\n",
      "loss: 0.5727518200874329 current: 12800\n",
      "loss: 0.7943581342697144 current: 19200\n",
      "loss: 0.6904025077819824 current: 25600\n",
      "loss: 0.6783061623573303 current: 32000\n",
      "loss: 0.7548978924751282 current: 38400\n",
      "loss: 0.7532516121864319 current: 44800\n",
      "loss: 0.7414153814315796 current: 51200\n",
      "loss: 0.7036235928535461 current: 57600\n",
      "Accuracy: 75.97333333333334 Avg loss: 0.6829252681816056\n",
      "Epoch::: 7\n",
      "---------------\n",
      "loss: 0.6623730063438416 current: 0\n",
      "loss: 0.756767213344574 current: 6400\n",
      "loss: 0.5304688215255737 current: 12800\n",
      "loss: 0.7614628076553345 current: 19200\n",
      "loss: 0.6628991961479187 current: 25600\n",
      "loss: 0.6479578018188477 current: 32000\n",
      "loss: 0.7151803374290466 current: 38400\n",
      "loss: 0.729410707950592 current: 44800\n",
      "loss: 0.7124006152153015 current: 51200\n",
      "loss: 0.6731072068214417 current: 57600\n",
      "Accuracy: 77.47 Avg loss: 0.6508458144247913\n",
      "Epoch::: 8\n",
      "---------------\n",
      "loss: 0.6195213794708252 current: 0\n",
      "loss: 0.717122495174408 current: 6400\n",
      "loss: 0.4971195459365845 current: 12800\n",
      "loss: 0.7342497110366821 current: 19200\n",
      "loss: 0.641300618648529 current: 25600\n",
      "loss: 0.6246535181999207 current: 32000\n",
      "loss: 0.680274248123169 current: 38400\n",
      "loss: 0.7098873257637024 current: 44800\n",
      "loss: 0.6902081370353699 current: 51200\n",
      "loss: 0.6467574238777161 current: 57600\n",
      "Accuracy: 78.59166666666667 Avg loss: 0.6236729113532028\n",
      "Epoch::: 9\n",
      "---------------\n",
      "loss: 0.585281491279602 current: 0\n",
      "loss: 0.6834979057312012 current: 6400\n",
      "loss: 0.4700698256492615 current: 12800\n",
      "loss: 0.7109723687171936 current: 19200\n",
      "loss: 0.6242073178291321 current: 25600\n",
      "loss: 0.6062942743301392 current: 32000\n",
      "loss: 0.650074303150177 current: 38400\n",
      "loss: 0.6945727467536926 current: 44800\n",
      "loss: 0.6737080812454224 current: 51200\n",
      "loss: 0.6237000226974487 current: 57600\n",
      "Accuracy: 79.47666666666666 Avg loss: 0.6005308690355785\n",
      "Epoch::: 10\n",
      "---------------\n",
      "loss: 0.5573500394821167 current: 0\n",
      "loss: 0.6549878120422363 current: 6400\n",
      "loss: 0.44782495498657227 current: 12800\n",
      "loss: 0.6905162930488586 current: 19200\n",
      "loss: 0.6101404428482056 current: 25600\n",
      "loss: 0.5915994048118591 current: 32000\n",
      "loss: 0.6243450045585632 current: 38400\n",
      "loss: 0.6834267973899841 current: 44800\n",
      "loss: 0.6618327498435974 current: 51200\n",
      "loss: 0.6032447814941406 current: 57600\n",
      "Accuracy: 80.10666666666667 Avg loss: 0.5807641599096978\n",
      "training done!!!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for i in range(epochs):\n",
    "    print(f'Epoch::: {i+1}\\n---------------')\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print('training done!!!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Load torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /Users/vivek.rawat/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:10<00:00, 53.7MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16()\n",
    "\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')\n",
    "\n",
    "model = torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
